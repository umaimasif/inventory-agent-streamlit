# -*- coding: utf-8 -*-
"""AgenticAI4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uHPgWNe6RrzYDPmVAXpfyTjMnmWC1X0B

**API**
"""

!!pip install litellm
# import os
# from google.colab import userdata
# import google.generativeai as genai

# api_key=userdata.get("GEMINI_API_KEY")
# os.environ["GEMINI_API_KEY"]=api_key
# genai.configure(api_key=os.environ["GEMINI_API_KEY"])

import os
import json
import os
from typing import List,Dict

from litellm import completion
from google.colab import userdata  # For Google Colab secrets

# Load Groq API key from Google Colab secrets
Groq_key = userdata.get('Groq_key').strip()
os.environ['GROQ_API_KEY'] = Groq_key  # Set environment variable

# Define Groq model (e.g., llama3 or mixtral)
MODEL = "groq/llama-3.1-8b-instant"

# Function to generate response using Groq
def generate_response(messages: List[Dict]) -> str:
    response = completion(
        model=MODEL,
        messages=messages,
        max_tokens=1024,
        custom_llm_provider="groq"
    )
    return response.choices[0].message.content

"""Template"""

import json
import time
import traceback
from litellm import completion
from dataclasses import dataclass, field
from typing import List, Callable, Dict, Any,Optional

@dataclass
class Prompt:
    messages: List[Dict] = field(default_factory=list)
    tools: List[Dict] = field(default_factory=list)
    metadata: dict = field(default_factory=dict)  # Fixing mutable default issue


def generate_response(prompt: Prompt) -> str:
    """Call LLM to get response"""

    messages = prompt.messages
    tools = prompt.tools

    result = None

    if not tools:
        response = completion(
            model="gemini/gemini-1.5-flash-1.5-flash",
            messages=messages,
            max_tokens=1024
        )
        result = response.choices[0].message.content
    else:
        response = completion(
            model="gemini/gemini-1.5-flash",
            messages=messages,
            tools=tools,
            max_tokens=1024
        )

        if response.choices[0].message.tool_calls:
            tool = response.choices[0].message.tool_calls[0]
            result = {
                "tool": tool.function.name,
                "args": json.loads(tool.function.arguments),
            }
            result = json.dumps(result)
        else:
            result = response.choices[0].message.content


    return result


@dataclass(frozen=True)
class Goal:
    priority: int
    name: str
    description: str


class Action:
    def __init__(self,
                 name: str,
                 function: Callable,
                 description: str,
                 parameters: Dict,
                 terminal: bool = False):
        self.name = name
        self.function = function
        self.description = description
        self.terminal = terminal
        self.parameters = parameters

    def execute(self, **args) -> Any:
        """Execute the action's function"""
        return self.function(**args)
    def tool_schema(self) -> Dict:
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters
            }
        }


class ActionRegistry:
    def __init__(self):
        self.actions = {}

    def register(self, action: Action):
        self.actions[action.name] = action

    def get_action(self, name: str) -> Optional[Action]:
        return self.actions.get(name, None)

    def get_actions(self) -> List[Action]:
        """Get all registered actions"""
        return list(self.actions.values())


class Memory:
    def __init__(self):
        self.items = []  # Basic conversation histor

    def add_memory(self, memory: dict):
        """Add memory to working memory"""
        self.items.append(memory)

    def get_memories(self, limit: int = None) -> List[Dict]:
        """Get formatted conversation history for prompt"""
        return self.items[:limit]

    def copy_without_system_memories(self):
        """Return a copy of the memory without system memories"""
        filtered_items = [m for m in self.items if m["type"] != "system"]
        memory = Memory()
        memory.items = filtered_items
        return memory


class Environment:
    def execute_action(self, action: Action, args: dict) -> dict:
        """Execute an action and return the result."""
        try:
            result = action.execute(**args)
            return self.format_result(result)
        except Exception as e:
            return {
                "tool_executed": False,
                "error": str(e),
                "traceback": traceback.format_exc()
            }

    def format_result(self, result: Any) -> dict:
        """Format the result with metadata."""
        return {
            "tool_executed": True,
            "result": result,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S%z")
        }


class AgentLanguage:
    def __init__(self):
        pass

    def construct_prompt(self,
                         actions: List[Action],
                         environment: Environment,
                         goals: List[Goal],
                         memory: Memory) -> Prompt:
        raise NotImplementedError("Subclasses must implement this method")


    def parse_response(self, response: str) -> dict:
        raise NotImplementedError("Subclasses must implement this method")



class AgentFunctionCallingActionLanguage(AgentLanguage):

    def __init__(self):
        super().__init__()

    def format_goals(self, goals: List[Goal]) -> List:
        # Map all goals to a single string that concatenates their description
        # and combine into a single message of type system
        sep = "\n-------------------\n"
        goal_instructions = "\n\n".join([f"{goal.name}:{sep}{goal.description}{sep}" for goal in goals])
        return [
            {"role": "system", "content": goal_instructions}
        ]

    def format_memory(self, memory: Memory) -> List:
        """Generate response from language model"""
        # Map all environment results to a role:user messages
        # Map all assistant messages to a role:assistant messages
        # Map all user messages to a role:user messages
        items = memory.get_memories()
        mapped_items = []
        for item in items:

            content = item.get("content", None)
            if not content:
                content = json.dumps(item, indent=4)

            if item["type"] == "assistant":
                mapped_items.append({"role": "assistant", "content": content})
            elif item["type"] == "environment":
                mapped_items.append({"role": "assistant", "content": content})
            else:
                mapped_items.append({"role": "user", "content": content})

        return mapped_items
        for item in reversed(memory.get_memories()):
          if item["type"] == "environment":
            print("\n🎯 Final Answer:", json.loads(item["content"]).get("result", "N/A"))
            break

    def format_actions(self, actions: List[Action]) -> [List,List]:
        """Generate response from language model"""

        tools = [
            {
                "type": "function",
                "function": {
                    "name": action.name,
                    # Include up to 1024 characters of the description
                    "description": action.description[:1024],
                    "parameters": action.parameters,
                },
            } for action in actions
        ]

        return tools

    def construct_prompt(self,
                         actions: List[Action],
                         environment: Environment,
                         goals: List[Goal],
                         memory: Memory) -> Prompt:

        prompt = []
        prompt += self.format_goals(goals)
        prompt += self.format_memory(memory)

        tools = self.format_actions(actions)

        return Prompt(messages=prompt, tools=tools)

    def adapt_prompt_after_parsing_error(self,
                                         prompt: Prompt,
                                         response: str,
                                         traceback: str,
                                         error: Any,
                                         retries_left: int) -> Prompt:

        return prompt

    def parse_response(self, response: str) -> dict:
        """Parse LLM response into structured format."""
        try:
            parsed = json.loads(response)
            # Valid tool call
            return parsed
        except Exception:
            # Not a tool call – just finish by calling terminate
            return {
                "tool": "terminate",
                "args": {"message": response.strip()}
            }

class Agent:
    def __init__(self,
                 goals: List[Goal],
                 agent_language: AgentLanguage,
                 action_registry: ActionRegistry,
                 generate_response: Callable[[Prompt], str],
                 environment: Environment):
        """
        Initialize an agent with its core GAME components
        """
        self.goals = goals
        self.generate_response = generate_response
        self.agent_language = agent_language
        self.actions = action_registry
        self.environment = environment

    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:
        """Build prompt with memory context"""
        return self.agent_language.construct_prompt(
            actions=actions.get_actions(),
            environment=self.environment,
            goals=goals,
            memory=memory
        )

    def get_action(self, response):
        invocation = self.agent_language.parse_response(response)
        action = self.actions.get_action(invocation["tool"])
        return action, invocation

    def should_terminate(self, response: str) -> bool:
        action_def, _ = self.get_action(response)
        return action_def.terminal

    def set_current_task(self, memory: Memory, task: str):
        memory.add_memory({"type": "user", "content": task})

    def update_memory(self, memory: Memory, response: str, result: dict):
        """
        Update memory with the agent's decision and the environment's response.
        """
        new_memories = [
            {"type": "assistant", "content": response},
            {"type": "environment", "content": json.dumps(result)}
        ]
        for m in new_memories:
            memory.add_memory(m)

    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:
        response = self.generate_response(full_prompt.messages, full_prompt.tools)
        return response

    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:
        memory = memory or Memory()
        self.set_current_task(memory, user_input)
        final_answer = None

        for _ in range(max_iterations):
            prompt = self.construct_prompt(self.goals, memory, self.actions)

            # Generate LLM response
            response = self.prompt_llm_for_action(prompt)

            # Skip empty response
            if not response.strip():
                break

            # Get action + arguments
            action, invocation = self.get_action(response)

            # Execute tool
            result = self.environment.execute_action(action, invocation["args"])

            # Extract final answer if it's a real result (not system/control message)
            if result["tool_executed"] and "result" in result:
                final_answer = result["result"]

            # Update memory
            self.update_memory(memory, response, result)

            # Check termination
            if self.should_terminate(response):
                break

        # Only print the final result once
        if final_answer:
            print("\n🎯 Final Answer:", final_answer)

        return memory

"""**INVENTORY** **MANAGEMENT** **AGENT**"""

import json, csv
from typing import List, Dict
from litellm import completion
import pandas as pd

# ========== Inventory and File Logic ==========

inventory = []

def add_item(name, color, category, quantity, price, brand=None, size=None):
    item = {
        "name": name,
        "color": color,
        "category": category,
        "quantity": quantity,
        "price": price,
        "brand": brand,
        "size": size,
    }
    inventory.append(item)
    return {
        "message": f"✅ Added {quantity} {color} {name}(s) in {category} at price {price}"
    }


def delete_item(name, color):
    global inventory
    filtered = [item for item in inventory if not (item['name'] == name and item['color'] == color)]
    if len(filtered) == len(inventory):
        return {"message": f"❌ No item named {color} {name} found"}
    inventory = filtered
    return {"message": f"🗑️ Deleted items with name {color} {name}"}

# ✅ Step 1: Order Item Function
orders = []  # Place this at the top of your notebook/file where you define inventory

def order_item(name: str, color: str, quantity: int, category: str, price: int, brand: str, size: str):
    order = {
        "name": name.lower(),
        "color": color.lower(),
        "quantity": quantity,
        "category": category.lower(),
        "price": price,
        "brand": brand.lower(),
        "size": size.lower()
    }
    inventory.append(order)
    orders.append(order)
    return {
        "message": f"🛍️ Ordered {quantity} {color} {name}(s) from brand {brand}, size {size}, category {category}, at price {price}"
    }
RESTOCK_THRESHOLD = 5
def restock_alert_tool() -> dict:
    alerts = []
    for item in inventory:
        if item["quantity"] < RESTOCK_THRESHOLD:
            alerts.append(
                f"⚠️ Low stock: {item['quantity']} {item['color']} {item['name']}(s) in {item['category']}. Consider restocking."
            )
    if alerts:
        return {"message": "\n".join(alerts)}
    else:
        return {"message": "✅ All items are sufficiently stocked."}

def generate_invoice() -> str:
    invoice_lines = []
    total_amount = 0
    for order in orders:
        line = f"- {order['quantity']} {order['size']} {order['name']}(s) of brand {order['brand']} at Rs.{order['price']} each → Rs.{order['price'] * order['quantity']}"
        invoice_lines.append(line)
        total_amount += order["price"] * order["quantity"]

    invoice_text = "\n".join(invoice_lines)
    invoice_text += f"\n🧾 Total: Rs.{total_amount}"
    return invoice_text

def save_inventory():
    with open("inventory.json", "w") as f:
        json.dump(inventory, f, indent=4)

    df = pd.DataFrame(inventory)
    df.to_csv("inventory.csv", index=False)

    invoice = generate_invoice()
    print("💾 Inventory saved to inventory.json and inventory.csv")

    if invoice:
        print("📄 Invoice Summary:")
        print(invoice)

    # ⬇️ Call restock check
    restock_alerts = check_restock(inventory)
    if restock_alerts:
        print("\n📦 Restock Alerts:")
        for alert in restock_alerts:
            print(alert)





def stop_agent():
    summary = {}
    for item in inventory:
        key = f"{item['color']} {item['name']}"
        summary[key] = summary.get(key, 0) + item["quantity"]
    summary_str = "\n".join([f"🧾 You added {v} {k}(s)" for k, v in summary.items()])
    return {"message": f"🛑 Agent stopped.\n{summary_str}"}

# ========== Action Registry ==========

class Action:
    def __init__(self, name, func, parameters):
        self.name = name
        self.func = func
        self.parameters = parameters

    def execute(self, **kwargs):
        return self.func(**kwargs)

class ActionRegistry:
    def __init__(self):
        self.actions = {}

    def register(self, action: Action):
        self.actions[action.name] = action

    def get(self, name):
        return self.actions.get(name)

# ========== Environment ==========

class Environment:
    def execute_action(self, action: Action, args: dict) -> dict:
        try:
            result = action.execute(**args)
            return {"tool_executed": True, "result": result}
        except Exception as e:
            return {"tool_executed": False, "error": str(e)}

# ========== Agent ==========

class Agent:
    def __init__(self, name, actions: ActionRegistry, environment: Environment):
        self.name = name
        self.actions = actions
        self.environment = environment
        self.memory = []

    def generate_response(self, user_input):
        response = completion(
            model="groq/llama3-70b-8192",
            messages=[{"role": "user", "content": user_input}],
            functions=[
                {
                    "name": "add_item",
                    "description": "Add an item to inventory",
                    "parameters": {
                        "type": "object",
                        "properties": {
                             "name": {"type": "string"},
                            "color": {"type": "string"},
                            "quantity": {"type": "integer"},
                            "category": {"type": "string"},
                            "brand": {"type": "string"},
                            "size": {"type": "string"},
                            "price": {"type": "number"}
                        },
                        "required": ["name", "color", "quantity", "category", "price"]
                    }
                },
                {
                    "name": "delete_item",
                    "description": "Delete items by name and color",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "name": {"type": "string"},
                            "color": {"type": "string"}
                        },
                        "required": ["name", "color"]
                    }
                },
                {
             "name": "order_item",
             "description": "Place an order for items including brand and size, and add to inventory and order list",
             "parameters": {
                 "type": "object",
                "properties": {
                     "name": {"type": "string", "description": "Name of the item"},
                    "color": {"type": "string", "description": "Color of the item"},
                     "quantity": {"type": "integer", "description": "How many items are ordered"},
                     "category": {"type": "string", "description": "Category like clothing, electronics etc"},
                      "price": {"type": "integer", "description": "Price of the item"},
                      "brand": {"type": "string", "description": "Brand name"},
                     "size": {"type": "string", "description": "Size of the item like small, medium, large"}
                  },
                 "required": ["name", "color", "quantity", "category", "price", "brand", "size"]
              }
}
,{

                    "name":"restock_alert_tool",
                    "description": "Check inventory for low stock",
                    "parameters": {"type": "object", "properties": {}}
},
                {
                    "name": "save_inventory",
                    "description": "Save inventory to disk",
                    "parameters": {"type": "object", "properties": {}}
                },
                {
                    "name": "stop_agent",
                    "description": "Stop the agent and show summary",
                    "parameters": {"type": "object", "properties": {}}
                }
            ],
            function_call="auto"
        )
        return response

    def run(self):
     print("Inventory Agent started. Tell me what do you want to: add, order, delete, save, stop. And if you want to check stock type 'restock'\n")
     while True:
        user_input = input("Type")
        response = self.generate_response(user_input)

        # If tool call
        if response.choices[0].finish_reason == "function_call":
            call = response.choices[0].message.function_call
            name = call.name
            args = json.loads(call.arguments)

            action = self.actions.get(name)
            if action:
                result = self.environment.execute_action(action, args)
                if result["tool_executed"]:
                    # ✅ Safe printing to avoid NoneType crash
                    if isinstance(result["result"], dict) and "message" in result["result"]:
                        print("🤖", result["result"]["message"])
                    elif result["result"] is not None:
                        print("🤖", result["result"])
                    if name == "stop_agent":
                        break
                else:
                    print("🤖 Tool failed:", result["error"])
            else:
                print("🤖 Unknown tool")
        else:
            print("🤖", response.choices[0].message.content)


# ========== Registering Actions ==========

registry = ActionRegistry()
registry.register(Action("add_item", add_item, None))
registry.register(Action("delete_item", delete_item, None))
registry.register(Action("save_inventory", save_inventory, None))
registry.register(Action("stop_agent", stop_agent, None))
registry.register(Action("order_item", order_item,None))
registry.register(Action("restock_alert_tool", restock_alert_tool, None))



# ========== Running Agent ==========

agent = Agent(name="InventoryAgent", actions=registry, environment=Environment())
agent.run()
